{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Kriging to Predict Ground Water Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pyro\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyro.optim as optim\n",
    "import pyro.contrib.gp as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from torch.distributions import constraints\n",
    "\n",
    "from functools import partial\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "\n",
    "# Enable validation checks\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(\n",
    "    plot_observed_data=False,\n",
    "    plot_predictions=False,\n",
    "    n_prior_samples=0,\n",
    "    model=None,\n",
    "    kernel=None,\n",
    "    n_test=500,\n",
    "):\n",
    "\n",
    "    ax = plt.figure().add_subplot(111, projection='3d')\n",
    "    \n",
    "    if plot_observed_data:\n",
    "        ax.scatter(XW[:, 0], XW[:, 1], YW, marker=\"x\")\n",
    "        ax.scatter(XF[:, 0], XF[:, 1], YF, marker=\"o\")\n",
    "        \n",
    "    if plot_predictions:\n",
    "        Xtest_ltd = torch.linspace(0, 5, n_test)\n",
    "        Xtest_lng = torch.linspace(0, 10, n_test)\n",
    "        \n",
    "        Xtest_ltd, Xtest_lng = np.meshgrid(Xtest_ltd, Xtest_lng)\n",
    "        \n",
    "        Xtest_ltd = np.expand_dims(Xtest_ltd, -1)\n",
    "        Xtest_lng = np.expand_dims(Xtest_lng, -1)\n",
    "        \n",
    "        Xtest = np.concatenate([Xtest_ltd, Xtest_lng], -1).reshape((-1, 2))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if type(model) == gp.models.VariationalSparseGP:\n",
    "                mean, cov = model(Xtest, full_cov=True)\n",
    "            else:\n",
    "                mean, cov = model(Xtest, full_cov=True, noiseless=False)\n",
    "                \n",
    "        print(mean, cov)\n",
    "                \n",
    "        sd = cov.diag().sqrt()  # standard deviation at each input point x\n",
    "        plt.plot(Xtest.numpy(), mean.numpy(), \"r\", lw=2)  # plot the mean\n",
    "        plt.fill_between(\n",
    "            Xtest,  # plot the two-sigma uncertainty about the mean\n",
    "            (mean - 2.0 * sd).numpy(),\n",
    "            (mean + 2.0 * sd).numpy(),\n",
    "            color=\"C0\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        \n",
    "    if n_prior_samples > 0:  # plot samples from the GP prior\n",
    "        Xtest_ltd = torch.linspace(0, 5, n_test)\n",
    "        Xtest_lng = torch.linspace(0, 10, n_test)\n",
    "        \n",
    "        Xtest_ltd, Xtest_lng = np.meshgrid(Xtest_ltd, Xtest_lng)\n",
    "        \n",
    "        Xtest_ltd = np.expand_dims(Xtest_ltd, -1)\n",
    "        Xtest_lng = np.expand_dims(Xtest_lng, -1)\n",
    "        \n",
    "        Xtest = np.concatenate([Xtest_ltd, Xtest_lng], -1).reshape((-1, 2))\n",
    "        Xtest = torch.tensor(Xtest)\n",
    "        \n",
    "        noise = (\n",
    "            model.noise\n",
    "            if type(model) != gp.models.VariationalSparseGP\n",
    "            else model.likelihood.variance\n",
    "        )\n",
    "        cov = kernel.forward(Xtest) + noise.expand(n_test).diag()\n",
    "        samples = dist.MultivariateNormal(\n",
    "            torch.zeros(n_test), covariance_matrix=cov\n",
    "        ).sample(sample_shape=(n_prior_samples,))\n",
    "        plt.plot(Xtest.numpy(), samples.numpy().T, lw=2, alpha=0.4)\n",
    "\n",
    "#     plt.xlim(-0.5, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_posterior(samples):\n",
    "    import math\n",
    "    \n",
    "    sites = list(samples.keys())\n",
    "    \n",
    "    r = int(math.ceil(math.sqrt(len(samples))))\n",
    "    fig, axs = plt.subplots(nrows=r, ncols=r, figsize=(12, 10))\n",
    "    fig.suptitle(\"Marginal Posterior Density\", fontsize=16)\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        site = sites[i]\n",
    "        sns.distplot(samples[site], ax=ax)\n",
    "        ax.set_title(site)\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample_data.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "data_wells = data[data.type == \"well\"]\n",
    "data_farms = data[data.type == \"farm\"]\n",
    "\n",
    "XW = torch.FloatTensor(data_wells[[\"latitude\", \"longitude\"]].values)\n",
    "YW = torch.FloatTensor(data_wells[\"observation\"].values)\n",
    "\n",
    "XF = torch.FloatTensor(data_farms[[\"latitude\", \"longitude\"]].values)\n",
    "YF = torch.FloatTensor(data_farms[\"observation\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(plot_observed_data=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    XW = XW.cuda()\n",
    "    YW = YW.cuda()\n",
    "\n",
    "    XF = XF.cuda()\n",
    "    YF = YF.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bayesian Kernel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model_kr(XW, YW, use_cuda=False):\n",
    "    mu_delta = torch.Tensor([1.0]).type_as(XW)\n",
    "    mu_theta = torch.Tensor([0.0]).type_as(XW)\n",
    "\n",
    "    delta = pyro.sample(\"delta\", dist.LogNormal(mu_delta, 0.5))\n",
    "    theta = pyro.sample(\"theta\", dist.LogNormal(mu_theta, 0.5))\n",
    "\n",
    "    sigma_mu = torch.Tensor([2.0]).type_as(XW)\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(0, sigma_mu))\n",
    "\n",
    "    a_sigma = torch.FloatTensor([1.0]).type_as(XW)\n",
    "    b_sigma = torch.FloatTensor([1.0]).type_as(XW)\n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(a_sigma, b_sigma))\n",
    "    mean = (\n",
    "        mu\n",
    "        - (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta\n",
    "    )\n",
    "\n",
    "    with pyro.plate(\"data\", len(YW)):\n",
    "        y = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=YW)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def guide_kr(XW, YW):\n",
    "    mu_delta = pyro.param(\"mu_delta\", torch.ones(1).type_as(XW), constraint=constraints.positive)\n",
    "    mu_theta = pyro.param(\"mu_theta\", torch.zeros(1).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    sg_delta = pyro.param(\"sg_delta\", torch.ones(1).type_as(XW), constraint=constraints.positive)\n",
    "    sg_theta = pyro.param(\"sg_theta\", torch.ones(1).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    delta = pyro.sample(\"delta\", dist.Normal(mu_delta, sg_delta))\n",
    "    theta = pyro.sample(\"theta\", dist.Normal(mu_theta, sg_theta))\n",
    "    \n",
    "#     mu_sigma = pyro.param(\"mu_sigma\", torch.tensor(1.0).type_as(XW), constraint=constraints.positive)\n",
    "#     sigma = pyro.sample(\"sigma\", dist.Gamma(mu_sigma, torch.tensor(1.0).type_as(XW)))\n",
    "    \n",
    "    mu_mu = pyro.param(\"mu_mu\", torch.randn(1).type_as(XW))\n",
    "    sg_mu = pyro.param(\"sg_mu\", torch.ones(1).type_as(XW), constraint=constraints.positive)\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(mu_mu, sg_mu))\n",
    "    \n",
    "    mean = mu - delta * (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict_kr(XW, posterior_samples):\n",
    "    ps = posterior_samples\n",
    "    samples = zip(ps[\"delta\"], ps[\"theta\"], ps[\"mu\"], ps[\"sigma\"])\n",
    "    \n",
    "    for delta, theta, mu, sigma in samples:\n",
    "        mean = mu - (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta\n",
    "        yield dist.Normal(mean, sigma).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(partial(model_kr, use_cuda=use_cuda))\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=2000)\n",
    "mcmc_run = mcmc.run(XW, YW)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_posterior(hmc_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "svi = SVI(\n",
    "    partial(model_kr, use_cuda=use_cuda), guide_kr, optim.Adam({\"lr\": 0.005}), loss=JitTrace_ELBO(), num_samples=1000\n",
    ")\n",
    "\n",
    "pyro.clear_param_store()\n",
    "num_iters = 10000 if not smoke_test else 2\n",
    "for i in range(num_iters):\n",
    "    elbo = svi.step(XW, YW)\n",
    "    if i % 500 == 0:\n",
    "        logging.info(\"Elbo loss: {}\".format(elbo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = torch.stack(list(predict_kr(XW, hmc_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(15, 15)).add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], YW, marker=\"x\")\n",
    "ax.scatter(XF[:, 0], XF[:, 1], YF, marker=\"^\")\n",
    "\n",
    "# for result in results[:100]:\n",
    "#     ax.scatter(XW[:, 0], XW[:, 1], result, marker=\".\", color=\"red\")\n",
    "    \n",
    "results_mean = results.mean(dim=0).numpy()\n",
    "results_std = results.std(dim=0).numpy()\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean, marker=\"o\", color=\"red\", s=15)\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean - results_std, marker=\"_\", color=\"green\", s=15)\n",
    "# for i, point in enumerate(XW.numpy().tolist()):\n",
    "#     ax.plot(point + [results_mean[i] + results_std[i]], point + [results_mean[i] - results_std[i]])\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean + results_std, marker=\"_\", color=\"green\", s=15)\n",
    "    \n",
    "plt.savefig(\"predictions.png\", dpi=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "YW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_gp(XW, YW):\n",
    "    mu_delta = torch.Tensor([1.0]).type_as(XW)\n",
    "    \n",
    "    delta = pyro.sample(\"delta\", dist.LogNormal(mu_delta, 0.5))\n",
    "    \n",
    "    mu_theta_f = torch.Tensor([0.0]).type_as(XW)\n",
    "    mu_theta_w = torch.Tensor([0.0]).type_as(XW)\n",
    "    \n",
    "    theta_f = pyro.sample(\"theta_f\", dist.LogNormal(mu_theta_f, 0.5))\n",
    "    theta_w = pyro.sample(\"theta_w\", dist.LogNormal(mu_theta_w, 0.5))\n",
    "    \n",
    "    sigma_mu = torch.Tensor([1.0]).type_as(XW)\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(0, sigma_mu))\n",
    "    \n",
    "    sigma = torch.exp(-pairwise_distances(XW, XW) / theta_w)\n",
    "    mean = mu - delta * (YF * torch.exp(-pairwise_distances(XW, XF) / theta_f)).sum(1)\n",
    "    \n",
    "    with pyro.plate(\"data\", len(YW)):\n",
    "        y = pyro.sample(\"obs\", dist.MultivariateNormal(mean, sigma), obs=YW)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide_gp(XW, YW):\n",
    "    mu_delta = pyro.param(\"mu_delta\", torch.Tensor([1.0]).type_as(XW), constraint=constraints.positive)\n",
    "    sg_delta = pyro.param(\"sg_delta\", torch.Tensor([1.0]).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    delta = -pyro.sample(\"delta\", dist.LogNormal(mu_delta, sg_delta))\n",
    "    \n",
    "    mu_theta_f = pyro.param(\"mu_theta_f\", torch.Tensor([0.0]).type_as(XW), constraint=constraints.positive)\n",
    "    mu_theta_w = pyro.param(\"mu_theta_w\", torch.Tensor([0.0]).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    sg_theta_f = pyro.param(\"sg_theta_f\", torch.Tensor([1.0]).type_as(XW), constraint=constraints.positive)\n",
    "    sg_theta_w = pyro.param(\"sg_theta_w\", torch.Tensor([1.0]).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    theta_f = pyro.sample(\"theta_f\", dist.LogNormal(mu_theta_f, sg_theta_f))\n",
    "    theta_w = pyro.sample(\"theta_w\", dist.LogNormal(mu_theta_w, sg_theta_w))\n",
    "    \n",
    "    mu_mu = pyro.param(\"mu_mu\", torch.randn(1).type_as(XW))\n",
    "    sg_mu = pyro.param(\"sg_mu\", torch.Tensor([1.0]).type_as(XW), constraint=constraints.positive)\n",
    "    \n",
    "    mu = pyro.sample(\"mu\", dist.Normal(mu_mu, sg_mu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_gp(XW, posterior_samples):\n",
    "    ps = posterior_samples\n",
    "    samples = zip(ps[\"delta\"], ps[\"theta_f\"], ps[\"theta_w\"], ps[\"mu\"])\n",
    "    \n",
    "    pdx = pairwise_distances(XW).cpu().numpy()\n",
    "    pdf = pairwise_distances(XW, XF).cpu().numpy()\n",
    "    \n",
    "    YF_ = YF.cpu().numpy()\n",
    "    \n",
    "    for delta, theta_f, theta_w, mu in samples:\n",
    "        sigma = np.exp(-pdx / theta_w)\n",
    "        mean = mu - delta * (YF_ * np.exp(-pdf / theta_f)).sum(1)\n",
    "        \n",
    "        yield np.random.multivariate_normal(mean, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(\"data/gp-samples.json\", \"r\") as f:\n",
    "        hmc_samples = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "        \n",
    "except:\n",
    "    nuts_kernel = NUTS(model_gp)\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=4000)\n",
    "    mcmc_run = mcmc.run(XW, YW)\n",
    "\n",
    "    hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "hmc_samples_ = {k: v.tolist() for k, v in hmc_samples.items()}\n",
    "with open(\"data/gp-samples.json\", \"w\") as f:\n",
    "    json.dump(hmc_samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_posterior(hmc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "results = np.array(list(predict_gp(XW, hmc_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(15, 15)).add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], YW_, marker=\"x\")\n",
    "ax.scatter(XF_[:, 0], XF_[:, 1], YF_, marker=\"^\")\n",
    "\n",
    "# for result in results[:100]:\n",
    "#     ax.scatter(XW[:, 0], XW[:, 1], result, marker=\".\", color=\"red\")\n",
    "\n",
    "results_mean = results.mean(axis=0)\n",
    "results_std = results.std(axis=0)\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean, marker=\"o\", color=\"red\", s=15)\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean - results_std, marker=\"_\", color=\"green\", s=15)\n",
    "# for i, point in enumerate(XW.numpy().tolist()):\n",
    "#     ax.plot(point + [results_mean[i] + results_std[i]], point + [results_mean[i] - results_std[i]])\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean + results_std, marker=\"_\", color=\"green\", s=15)\n",
    "    \n",
    "plt.savefig(\"predictions.png\", dpi=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(\n",
    "    model_gp, guide_gp, optim.Adagrad({\"lr\": 0.01}), loss=JitTrace_ELBO(), num_samples=1000\n",
    ")\n",
    "\n",
    "pyro.clear_param_store()\n",
    "num_iters = 10000 if not smoke_test else 2\n",
    "for i in range(num_iters):\n",
    "    elbo = svi.step(XW, YW)\n",
    "    if i % 500 == 0:\n",
    "        logging.info(\"Elbo loss: {}\".format(elbo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi_diagnorm_posterior = svi.run(XW, YW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites = [\"delta\", \"theta_f\", \"theta_w\", \"mu\"]\n",
    "\n",
    "svi_samples = {\n",
    "    site: EmpiricalMarginal(svi_diagnorm_posterior, sites=site)\n",
    "    .enumerate_support()\n",
    "    .detach()\n",
    "    .cpu()\n",
    "    .numpy()\n",
    "    for site in sites\n",
    "}\n",
    "\n",
    "for site, values in summary(svi_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(list(predict_gp(XW, svi_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XW_ = XW.cpu().numpy()\n",
    "YW_ = YW.cpu().numpy()\n",
    "\n",
    "XF_ = XF.cpu().numpy()\n",
    "YF_ = YF.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(15, 15)).add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], YW_, marker=\"x\")\n",
    "ax.scatter(XF_[:, 0], XF_[:, 1], YF_, marker=\"^\")\n",
    "\n",
    "# for result in results[:100]:\n",
    "#     ax.scatter(XW[:, 0], XW[:, 1], result, marker=\".\", color=\"red\")\n",
    "\n",
    "results_mean = results.mean(axis=0)\n",
    "results_std = results.std(axis=0)\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean, marker=\"o\", color=\"red\", s=15)\n",
    "\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean - results_std, marker=\"_\", color=\"green\", s=15)\n",
    "# for i, point in enumerate(XW.numpy().tolist()):\n",
    "#     ax.plot(point + [results_mean[i] + results_std[i]], point + [results_mean[i] - results_std[i]])\n",
    "ax.scatter(XW_[:, 0], XW_[:, 1], results_mean + results_std, marker=\"_\", color=\"green\", s=15)\n",
    "    \n",
    "plt.savefig(\"predictions.png\", dpi=240)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
