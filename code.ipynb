{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ground Water Levels with Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pyro\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyro.optim as optim\n",
    "import pyro.contrib.gp as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from torch.distributions import constraints\n",
    "\n",
    "from functools import partial\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import Image, Video\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "\n",
    "# Enable validation checks\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_posterior(samples):\n",
    "    import math\n",
    "    \n",
    "    sites = list(samples.keys())\n",
    "    \n",
    "    r = int(math.ceil(math.sqrt(len(samples))))\n",
    "    fig, axs = plt.subplots(nrows=r, ncols=r, figsize=(15, 13))\n",
    "    fig.suptitle(\"Marginal Posterior Density\", fontsize=16)\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        if i >= len(sites):\n",
    "            break\n",
    "        site = sites[i]\n",
    "        sns.distplot(samples[site], ax=ax)\n",
    "        ax.set_title(site)\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Model\n",
    "---\n",
    "**Farm Factor**\n",
    "\\begin{align*}\n",
    "    \\ln(\\delta) \\sim \\mathcal{N}(1.0, 0.5)\n",
    "\\end{align*}\n",
    "\n",
    "**Distance Factors**\n",
    "\\begin{align*}\n",
    "    \\ln(\\theta_w) \\sim \\mathcal{N}(0.0, 0.5) \\\\\n",
    "    \\ln(\\theta_f) \\sim \\mathcal{N}(0.0, 0.5)\n",
    "\\end{align*}\n",
    "\n",
    "**Variance**\n",
    "\\begin{align*}\n",
    "    \\sigma^2 \\sim \\text{Gam}(1.0, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Seasonal Factors**\n",
    "For season $s \\in \\mathcal{S}$\n",
    "\\begin{align*}\n",
    "    \\gamma_s \\sim \\mathcal{N}(0.0, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Base Water Levels**\n",
    "\n",
    "The base water levels are modeled as a simple AR(1) process. The details of this are as follows\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mu_0 \\sim \\mathcal{N}(\\gamma_{s_0}, 1.0) \\\\\n",
    "\\end{align*}\n",
    "For $t = 1 \\dots T$, we specify\n",
    "\\begin{align*}\n",
    "    \\mu_{t} \\sim \\mathcal{N}(\\mu_{t - 1} + \\gamma_{s_t}, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Likelihood**\n",
    "\n",
    "For $t = 0 \\dots T$, we specify\n",
    "\\begin{align*}\n",
    "    \\mathbf{y}_t \\sim \\mathcal{N}(\\mu_t - \\delta \\cdot K(X_{t,w}, X_{t,f})\\ /\\ \\theta_f, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"includes/hmm-model.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seasons=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(XW, YW, YF, WF_distances, n_seasons=4, seasons=None, gp=False):\n",
    "    assert not torch._C._get_tracing_state()\n",
    "\n",
    "    delta = pyro.sample(\"delta\", dist.LogNormal(1.0, 0.5))\n",
    "\n",
    "    if gp:\n",
    "        theta_w = pyro.sample(\"theta_w\", dist.LogNormal(0.0, 0.5))    \n",
    "    else:\n",
    "        sigma = pyro.sample(\"sigma\", dist.Gamma(1.0, 1.0))\n",
    "    \n",
    "    theta_f = pyro.sample(\"theta_f\", dist.LogNormal(0.0, 0.5))\n",
    "    \n",
    "    sf = pyro.sample(\"sf\", dist.Normal(torch.zeros(n_seasons), 1.0))\n",
    "    if seasons is None:\n",
    "        seasons = np.tile(np.arange(n_seasons), int(len(YW) / n_seasons + 1))[:len(YW)]\n",
    "\n",
    "    mu = 0\n",
    "    for t in pyro.markov(range(len(YW))):\n",
    "        if gp:\n",
    "            sigma = torch.exp(-pairwise_distances(XW[t], XW[t]) / theta_w)\n",
    "                \n",
    "        mu = pyro.sample(\n",
    "            \"mu_{}\".format(t), dist.Normal(mu + sf[seasons[t]], 1.0)\n",
    "        )\n",
    "        \n",
    "        mean = mu - delta * torch.mm(torch.exp(-WF_distances[t] / theta_f), YF[t])\n",
    "        \n",
    "        if gp:\n",
    "            pyro.sample(\n",
    "                \"obs_{}\".format(t), dist.MultivariateNormal(mean, sigma), obs=YW[t]\n",
    "            )\n",
    "        else:\n",
    "            with pyro.plate(\"data_{}\".format(t), len(YW[t])):\n",
    "                pyro.sample(\n",
    "                    \"obs_{}\".format(t), dist.Normal(mean, sigma), obs=YW[t]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict1(XW, XF, YF, samples, n_seasons=4, seasons=None, gp=False, recon=False):\n",
    "    sigma = samples[\"sigma\"]\n",
    "    delta = samples[\"delta\"]\n",
    "    \n",
    "    if gp:\n",
    "        theta_w = samples[\"theta_w\"]\n",
    "        \n",
    "    theta_f = samples[\"theta_f\"]\n",
    "    \n",
    "    sf = samples[\"sf\"]\n",
    "    if seasons is None:\n",
    "        seasons = np.tile(np.arange(n_seasons), int(len(YW) / n_seasons + 1))[:len(YW)]\n",
    "    \n",
    "    mu = list(zip(*[samples[\"mu_{}\".format(i)] for i in range(len(YF))]))\n",
    "    mu = np.array(mu)\n",
    "    \n",
    "    samples = []\n",
    "    for t in range(len(YF)):\n",
    "        YF_ = YF[t].cpu().numpy()\n",
    "        \n",
    "        if gp:\n",
    "            pdx = pairwise_distances(XW[t]).cpu().numpy()\n",
    "        pdf = pairwise_distances(XW[t], XF[t]).cpu().numpy()\n",
    "    \n",
    "        samples_ = []\n",
    "        for i in range(len(delta)):\n",
    "            if gp:\n",
    "                sg = np.exp(-pdx / theta_w[i])\n",
    "            else:\n",
    "                sg = sigma[i]\n",
    "                \n",
    "            mean = mu[i, t] - delta[i] * np.matmul(np.exp(-pdf / theta_f[i]), YF_) + sf[i][seasons[t]]\n",
    "            if recon:\n",
    "                samples_.append(mean)\n",
    "            else:\n",
    "                samples_.append(np.random.normal(mean, sg))\n",
    "            \n",
    "        samples_ = np.array(samples_)\n",
    "        samples.append(samples_)\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample-data/data.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "data_wells = data[data.type == \"well\"]\n",
    "data_farms = data[data.type == \"farm\"]\n",
    "\n",
    "XW, YW = [], []\n",
    "for t in data_wells[\"timestep\"].unique():\n",
    "    data_ = data_wells[data_wells[\"timestep\"] == t]\n",
    "\n",
    "    XW.append(data_[[\"latitude\", \"longitude\"]].values)\n",
    "    YW.append(data_[\"observation\"].values)\n",
    "    \n",
    "XW = XW[0]\n",
    "\n",
    "XF = data_farms[[\"latitude\", \"longitude\"]].values\n",
    "YF = data_farms[\"observation\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "plt.scatter(XF[:, 0], XF[:, 1], marker=\"s\", s=7, color=\"lightgreen\")\n",
    "\n",
    "scat = plt.scatter(XW[:, 0], XW[:, 1], marker=\"s\", s=20, c=[(0, 0, 0, 1)] * len(XW))\n",
    "label = plt.text(0, 0, '', fontsize=12)\n",
    "\n",
    "colors = []\n",
    "for obs in YW:\n",
    "    colors.append([min(1 - abs(x) / 15, 1) for x in obs])\n",
    "    \n",
    "colors = np.array(colors)\n",
    "\n",
    "def update_plot(i, scat):\n",
    "    scat.set_array(colors[i])\n",
    "    label.set_text([\"Sp\", \"Su\", \"Fa\", \"Wi\"][i % 4])\n",
    "    return scat,\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=range(len(XW)), fargs=(scat,), interval=1000)\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"includes/sample-data-animation.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"includes/sample-data-animation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XW = torch.tensor(XW)\n",
    "YW = torch.tensor(YW)[..., None]\n",
    "\n",
    "XF = torch.tensor(XF)\n",
    "YF = torch.tensor(YF)[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(YW)\n",
    "\n",
    "XW = XW.repeat(timesteps, 1, 1)\n",
    "\n",
    "YF = YF.repeat(timesteps, 1, 1)\n",
    "XF = XF.repeat(timesteps, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "use_gp = False\n",
    "save_samples = True\n",
    "\n",
    "samples_file = \"data/sample-data/\" + (\"gp-samples\" if use_gp else \"kr-samples\") + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(samples_file, \"r\") as f:\n",
    "        samples = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "except:\n",
    "    print(\"Failed to load samples file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    WF_distances = [pairwise_distances(XW[i], XF[i]) for i in range(len(YW))]\n",
    "\n",
    "    nuts_kernel = NUTS(partial(model1, n_seasons=4, WF_distances=WF_distances, gp=use_gp))\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "    mcmc_run = mcmc.run(XW, YW, YF)\n",
    "\n",
    "    samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_samples:\n",
    "    samples_ = {k: v.tolist() for k, v in samples.items()}\n",
    "    with open(samples_file, \"w\") as f:\n",
    "        json.dump(samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site, values in summary(samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset.pkl\", \"rb\") as f:\n",
    "    XF_r = [np.array(x) for x in pickle.load(f)]\n",
    "    YF_r = [np.array(x) for x in pickle.load(f)]\n",
    "                        \n",
    "    XW_r = [np.array(x) for x in pickle.load(f)]\n",
    "    YW_r = [np.array(x) for x in pickle.load(f)]\n",
    "    \n",
    "    XS_r = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "scat_f = plt.scatter(XF_r[0][:, 0], XF_r[0][:, 1], marker=\"s\", s=7, color=\"lightgreen\")\n",
    "\n",
    "scat_w = plt.scatter(XW_r[0][:, 0], XW_r[0][:, 1], marker=\"s\", s=20, c=[(0, 0, 0, 1)] * len(XW_r[0]))\n",
    "label = plt.text(0, 0, '', fontsize=12)\n",
    "\n",
    "def update_plot(i, scat_w, scat_f):\n",
    "    scat_w.set_offsets(XW_r[i])\n",
    "    scat_w.set_array(np.array([min(1 - abs(x[0]) / 50, 1) for x in YW_r[i]]))\n",
    "    \n",
    "    scat_f.set_offsets(XF_r[i])\n",
    "    return scat_w, scat_f\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=range(len(XW_r)), fargs=(scat_w, scat_f), interval=1000)\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"includes/data-animation.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"includes/data-animation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XF_r = [torch.tensor(x) for x in XF_r]\n",
    "YF_r = [torch.tensor(x) for x in YF_r]\n",
    "\n",
    "XW_r = [torch.tensor(x) for x in XW_r]\n",
    "YW_r = [torch.tensor(x) for x in YW_r]\n",
    "\n",
    "XS_r = torch.tensor(XS_r) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.cat(XW_r + XF_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = Xs.mean(0)\n",
    "x_std = Xs.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XW_r = [(x - x_mean) / x_std for x in XW_r]\n",
    "XF_r = [(x - x_mean) / x_std for x in XF_r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "use_gp = False\n",
    "save_samples = True\n",
    "\n",
    "samples_file = \"data/real-data/\" + (\"gp-samples\" if use_gp else \"kr-samples\") + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(samples_file, \"r\") as f:\n",
    "        samples = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "except:\n",
    "    print(\"Failed to load samples file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    WF_distances = [pairwise_distances(XW_r[i], XF_r[i]) for i in range(len(YW_r))]\n",
    "\n",
    "    nuts_kernel = NUTS(partial(model1, n_seasons=3, seasons=XS_r, WF_distances=WF_distances, gp=use_gp))\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "    mcmc_run = mcmc.run(XW_r, YW_r, YF_r)\n",
    "\n",
    "    samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_samples:\n",
    "    samples_ = {k: v.tolist() for k, v in samples.items()}\n",
    "    with open(samples_file, \"w\") as f:\n",
    "        json.dump(samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for site, values in summary(samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(XW, YW, YF, WF_distances, n_seasons=3, seasons=None):\n",
    "    assert not torch._C._get_tracing_state()\n",
    "\n",
    "    delta_c = pyro.sample(\"delta_c\", dist.LogNormal(1.0, 0.5))\n",
    "    delta_p = pyro.sample(\"delta_p\", dist.LogNormal(1.0, 0.5))\n",
    "\n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(1.0, 1.0))\n",
    "    theta_f = pyro.sample(\"theta_f\", dist.LogNormal(1.0, 0.5))\n",
    "\n",
    "    sf = pyro.sample(\"sf\", dist.Normal(torch.zeros(n_seasons), 1.0))\n",
    "    if seasons is None:\n",
    "        seasons = np.tile(np.arange(n_seasons), int(len(YW) / n_seasons + 1))[:len(YW)]\n",
    "\n",
    "    y = YW[0]\n",
    "    ff = torch.mm(torch.exp(-WF_distances[0] / theta_f), YF[0])\n",
    "\n",
    "    for t in pyro.markov(range(1, len(YW))):\n",
    "        with pyro.plate(\"data_{}\".format(t), len(YW[t])):\n",
    "            mean = y - delta_p * ff + sf[seasons[t]]\n",
    "            ff = torch.mm(torch.exp(-WF_distances[t] / theta_f), YF[t])\n",
    "\n",
    "            mean -= delta_c * ff\n",
    "\n",
    "            y = pyro.sample(\"obs_{}\".format(t), dist.Normal(mean, sigma), obs=YW[t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict2(XW, XF, YF, samples, n_seasons=3, seasons=None, recon=False):\n",
    "    sigma = samples[\"sigma\"]\n",
    "    delta_c = samples[\"delta_c\"]\n",
    "    delta_p = samples[\"delta_p\"]\n",
    "\n",
    "    theta_f = samples[\"theta_f\"]\n",
    "\n",
    "    sf = samples[\"sf\"]\n",
    "    if seasons is None:\n",
    "        seasons = np.tile(np.arange(n_seasons), int(len(YW) / n_seasons + 1))[:len(YW)]\n",
    "    \n",
    "    YF = [x.cpu().numpy() for x in YF]\n",
    "\n",
    "    samples = []\n",
    "    samples_ = [0] * len(sigma)\n",
    "    for t in range(1, len(YF)):\n",
    "        pdf_c = pairwise_distances(XW[t], XF[t]).cpu().numpy()\n",
    "        pdf_p = pairwise_distances(XW[t - 1], XF[t - 1]).cpu().numpy()\n",
    "\n",
    "        for i in range(len(sigma)):\n",
    "            sg = sigma[i]\n",
    "            mean = (\n",
    "                samples_[i]\n",
    "                - delta_c[i] * np.matmul(np.exp(-pdf_c / theta_f[i]), YF[t])\n",
    "                - delta_p[i] * np.matmul(np.exp(-pdf_p / theta_f[i]), YF[t-1])\n",
    "                + sf[i][seasons[t]]\n",
    "            )\n",
    "\n",
    "            if recon:\n",
    "                samples_[i] = mean\n",
    "            else:\n",
    "                samples_[i] = np.random.normal(mean, sg)\n",
    "\n",
    "        samples_ = np.array(samples_)\n",
    "        samples.append(samples_)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = XW_r[0]\n",
    "\n",
    "for arr in XW_r[1:]:\n",
    "    indices = torch.zeros(len(arr), dtype = torch.bool)\n",
    "    for elem in intersection:\n",
    "        indices = indices | (torch.abs(arr - elem).sum(1) < 1e-8)\n",
    "    intersection = arr[indices]\n",
    "    \n",
    "for i in range(len(XW_r)):\n",
    "    indices = torch.zeros(len(XW_r[i]), dtype = torch.bool)\n",
    "    for elem in intersection:\n",
    "        indices = indices | (torch.abs(XW_r[i] - elem).sum(1) < 1e-8)\n",
    "        \n",
    "    XW_r[i] = XW_r[i][indices]\n",
    "    YW_r[i] = YW_r[i][indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "save_samples = True\n",
    "\n",
    "samples_file = \"data/real-data/\" + \"alt-samples\" + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(samples_file, \"r\") as f:\n",
    "        samples = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "except:\n",
    "    print(\"Failed to load samples file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    WF_distances = [pairwise_distances(XW_r[i], XF_r[i]) for i in range(len(YW_r))]\n",
    "\n",
    "    nuts_kernel = NUTS(partial(model2, seasons=XS_r, WF_distances=WF_distances))\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "    mcmc_run = mcmc.run(XW_r, YW_r, YF_r)\n",
    "\n",
    "    samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_samples:\n",
    "    samples_ = {k: v.tolist() for k, v in samples.items()}\n",
    "    with open(samples_file, \"w\") as f:\n",
    "        json.dump(samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for site, values in summary(samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict2(XW_r, XF_r, YF_r, samples, recon=True)\n",
    "preds = np.array(preds).mean(1)\n",
    "\n",
    "preds = [YW_r[0].cpu().numpy()] + list(preds)\n",
    "for i in range(1, len(preds)):\n",
    "    preds[i] = np.minimum(preds[i] + preds[i - 1], 0)\n",
    "    \n",
    "preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([x.cpu().numpy() for x in YW_r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.concatenate((x, preds), axis=2)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
