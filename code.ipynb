{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ground Water Levels with Kernel Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pyro\n",
    "import torch\n",
    "import pickle\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyro.optim as optim\n",
    "import pyro.contrib.gp as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from torch.distributions import constraints\n",
    "\n",
    "from functools import partial\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import Image, Video\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "\n",
    "# Enable validation checks\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    dist = torch.clamp(dist, 0.0, np.inf)\n",
    "    \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_posterior(samples):\n",
    "    import math\n",
    "    \n",
    "    sites = list(samples.keys())\n",
    "    \n",
    "    r = int(math.ceil(math.sqrt(len(samples))))\n",
    "    fig, axs = plt.subplots(nrows=r, ncols=r, figsize=(15, 13))\n",
    "    fig.suptitle(\"Marginal Posterior Density\", fontsize=16)\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        if i >= len(sites):\n",
    "            break\n",
    "        site = sites[i]\n",
    "        sns.distplot(samples[site], ax=ax)\n",
    "        ax.set_title(site)\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative Model\n",
    "---\n",
    "**Farm Factor**\n",
    "\\begin{align*}\n",
    "    \\ln(\\delta) \\sim \\mathcal{N}(1.0, 0.5)\n",
    "\\end{align*}\n",
    "\n",
    "**Distance Factors**\n",
    "\\begin{align*}\n",
    "    \\ln(\\theta_w) \\sim \\mathcal{N}(0.0, 0.5) \\\\\n",
    "    \\ln(\\theta_f) \\sim \\mathcal{N}(0.0, 0.5)\n",
    "\\end{align*}\n",
    "\n",
    "**Variance**\n",
    "\\begin{align*}\n",
    "    \\sigma^2 \\sim \\text{Gam}(1.0, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Seasonal Factors**\n",
    "For season $s \\in \\mathcal{S}$\n",
    "\\begin{align*}\n",
    "    \\gamma_s \\sim \\mathcal{N}(0.0, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Base Water Levels**\n",
    "\n",
    "The base water levels are modeled as a simple AR(1) process. The details of this are as follows\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mu_0 \\sim \\mathcal{N}(\\gamma_{s_0}, 1.0) \\\\\n",
    "\\end{align*}\n",
    "For $t = 1 \\dots T$, we specify\n",
    "\\begin{align*}\n",
    "    \\mu_{t} \\sim \\mathcal{N}(\\mu_{t - 1} + \\gamma_{s_t}, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "**Likelihood**\n",
    "\n",
    "For $t = 0 \\dots T$, we specify\n",
    "\\begin{align*}\n",
    "    \\mathbf{y}_t \\sim \\mathcal{N}(\\mu_t - \\delta \\cdot K(X_{t,w}, X_{t,f})\\ /\\ \\theta_f, 1.0)\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"includes/hmm-model.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(XW, YW, YF, WF_distances, gp=False):\n",
    "    assert not torch._C._get_tracing_state()\n",
    "\n",
    "    delta = pyro.sample(\"delta\", dist.LogNormal(1.0, 0.5))\n",
    "\n",
    "    if gp:\n",
    "        theta_w = pyro.sample(\"theta_w\", dist.LogNormal(0.0, 0.5))    \n",
    "    else:\n",
    "        sigma = pyro.sample(\"sigma\", dist.Gamma(1.0, 1.0))\n",
    "    \n",
    "    theta_f = pyro.sample(\"theta_f\", dist.LogNormal(0.0, 0.5))\n",
    "    \n",
    "    n_seasons = 3\n",
    "    sf = pyro.sample(\"sf\", dist.Normal(torch.zeros(n_seasons), 1.0))\n",
    "\n",
    "    data_plate = pyro.plate(\"data\", len(YW[0]))\n",
    "        \n",
    "    mu = 0\n",
    "    for t in pyro.markov(range(len(YW))):\n",
    "        if gp:\n",
    "            sigma = torch.exp(-pairwise_distances(XW[t], XW[t]) / theta_w)\n",
    "                \n",
    "        mu = pyro.sample(\n",
    "            \"mu_{}\".format(t), dist.Normal(mu + sf[t % n_seasons], 1.0)\n",
    "        )\n",
    "        \n",
    "        mean = mu - delta * (YF[t] * torch.exp(-WF_distances[t] / theta_f)).sum(1)\n",
    "        \n",
    "        if gp:\n",
    "            pyro.sample(\n",
    "                \"obs_{}\".format(t), dist.MultivariateNormal(mean, sigma), obs=YW[t]\n",
    "            )\n",
    "        else:\n",
    "            with pyro.plate(\"data_{}\".format(t), len(YW[t])):\n",
    "#             with data_plate:\n",
    "                pyro.sample(\n",
    "                    \"obs_{}\".format(t), dist.Normal(mean, sigma), obs=YW[t]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(XW, XF, YF, samples, gp=False):\n",
    "        \n",
    "    sigma = samples[\"sigma\"]\n",
    "    delta = samples[\"delta\"]\n",
    "    \n",
    "    if gp:\n",
    "        theta_w = samples[\"theta_w\"]\n",
    "        \n",
    "    theta_f = samples[\"theta_f\"]\n",
    "    \n",
    "    mu = list(zip(*[samples[\"mu_{}\".format(i)] for i in range(len(YF))]))\n",
    "    mu = np.array(mu)\n",
    "    \n",
    "    samples = []\n",
    "    for t in range(len(YF)):\n",
    "        YF_ = YF[t].cpu().numpy()\n",
    "        \n",
    "        if gp:\n",
    "            pdx = pairwise_distances(XW[t]).cpu().numpy()\n",
    "        pdf = pairwise_distances(XW[t], XF[t]).cpu().numpy()\n",
    "    \n",
    "        samples_ = []\n",
    "        for i in range(len(delta)):\n",
    "            if gp:\n",
    "                sg = np.exp(-pdx / theta_w[i])\n",
    "            else:\n",
    "                sg = sigma[i]\n",
    "                \n",
    "            mean = mu[i, t] - delta[i] * (YF_ * np.exp(-pdf / theta_f[i])).sum(1)\n",
    "            samples_.append(np.random.normal(mean, sg))\n",
    "            \n",
    "        samples_ = np.array(samples_)\n",
    "        samples.append(samples_)\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = list(predict(XW_r, XF_r, YF_r, samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [x.mean(0) for x in vals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-34.04215076, -32.16421496, -40.46766094, -33.21190748,\n",
       "       -30.72401199, -34.06916408, -34.60869695, -35.92405091,\n",
       "       -37.24654335, -37.10247457, -35.52356699, -35.22256515,\n",
       "       -33.73864122, -32.91149726, -35.33260415, -30.35373844,\n",
       "       -33.57927149, -35.2426191 , -37.01480677, -34.21382468,\n",
       "       -35.21576545, -34.21334367, -35.9983931 , -36.81179993,\n",
       "       -34.49353128, -30.97596572, -31.5107213 , -30.92422419,\n",
       "       -36.18588612])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -48.0700],\n",
       "        [  -9.1000],\n",
       "        [  -6.4500],\n",
       "        [ -17.6000],\n",
       "        [ -19.2000],\n",
       "        [ -25.1500],\n",
       "        [ -27.2400],\n",
       "        [ -30.1400],\n",
       "        [ -19.7000],\n",
       "        [ -62.9000],\n",
       "        [ -33.8000],\n",
       "        [ -54.3400],\n",
       "        [  -9.4800],\n",
       "        [ -59.3500],\n",
       "        [ -17.7900],\n",
       "        [-116.0000],\n",
       "        [ -42.3800],\n",
       "        [ -56.2300],\n",
       "        [ -11.9600],\n",
       "        [ -10.1000],\n",
       "        [ -23.6200],\n",
       "        [ -58.3600],\n",
       "        [ -35.6300],\n",
       "        [ -10.8000],\n",
       "        [ -20.6500],\n",
       "        [ -13.6000],\n",
       "        [ -31.1300],\n",
       "        [ -45.1000],\n",
       "        [ -55.9500]], dtype=torch.float64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YW_r[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.2417, 71.5125], dtype=torch.float64)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XW_r[0][13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26.4917, 71.4875], dtype=torch.float64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XW_r[9][-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-37.85402207593267, -47.5),\n",
       " (-33.796590227095365, -7.48),\n",
       " (-35.82105790583092, -8.46),\n",
       " (-28.69468870735836, -16.86),\n",
       " (-36.180533210067715, -18.66),\n",
       " (-34.54529134760516, -27.1),\n",
       " (-32.11504513310349, -38.2),\n",
       " (-34.814679529821426, -27.59),\n",
       " (-32.13170505063718, -31.48),\n",
       " (-33.18659539250355, -36.6),\n",
       " (-30.36204796858018, -23.21),\n",
       " (-35.240600699269706, -33.8),\n",
       " (-30.60654545548461, -96.66),\n",
       " (-33.99185626099613, -54.6),\n",
       " (-33.06156273940035, -9.3),\n",
       " (-32.545093419191005, -60.96),\n",
       " (-36.7138313979355, -17.94),\n",
       " (-34.24093436774197, -11.6),\n",
       " (-30.27672985189944, -8.0),\n",
       " (-35.70648081151071, -23.0),\n",
       " (-27.727470908460806, -68.5),\n",
       " (-35.45589645161391, -21.4),\n",
       " (-42.757901745158954, -10.4),\n",
       " (-33.707175380736125, -20.5),\n",
       " (-31.330760264190914, -13.9),\n",
       " (-32.72187281194161, -32.9),\n",
       " (-27.10393087564684, -43.2),\n",
       " (-30.06646489546819, -57.2)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(vals[9], YW_r[9][:, 0].cpu().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'transpose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c14860298d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'transpose'"
     ]
    }
   ],
   "source": [
    "vals = vals.transpose(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-e7297f426e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "for i in range(len(vals)):\n",
    "    print(vals.mean(0)[i], y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample-data/data.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "data_wells = data[data.type == \"well\"]\n",
    "data_farms = data[data.type == \"farm\"]\n",
    "\n",
    "XW, YW = [], []\n",
    "for t in data_wells[\"timestep\"].unique():\n",
    "    data_ = data_wells[data_wells[\"timestep\"] == t]\n",
    "\n",
    "    XW.append(data_[[\"latitude\", \"longitude\"]].values)\n",
    "    YW.append(data_[\"observation\"].values)\n",
    "    \n",
    "XW = XW[0]\n",
    "\n",
    "XF = data_farms[[\"latitude\", \"longitude\"]].values\n",
    "YF = data_farms[\"observation\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "plt.scatter(XF[:, 0], XF[:, 1], marker=\"s\", s=7, color=\"lightgreen\")\n",
    "\n",
    "scat = plt.scatter(XW[:, 0], XW[:, 1], marker=\"s\", s=20, c=[(0, 0, 0, 1)] * len(XW))\n",
    "label = plt.text(0, 0, '', fontsize=12)\n",
    "\n",
    "colors = []\n",
    "for obs in YW:\n",
    "#     min_v = min(obs)\n",
    "#     max_v = max(obs)\n",
    "#     colors.append([max((x - min_v) / (max_v - min_v), 0.1) for x in obs])\n",
    "    colors.append([min(1 - abs(x) / 15, 1) for x in obs])\n",
    "    \n",
    "colors = np.array(colors)\n",
    "\n",
    "def update_plot(i, scat):\n",
    "    scat.set_array(colors[i])\n",
    "    label.set_text([\"Sp\", \"Su\", \"Fa\", \"Wi\"][i % 4])\n",
    "    return scat,\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=range(len(XW)), fargs=(scat,), interval=1000)\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim.save(\"includes/sample-data-animation.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Video(\"includes/sample-data-animation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XW = torch.tensor(XW)\n",
    "YW = torch.tensor(YW)\n",
    "\n",
    "XF = torch.tensor(XF)\n",
    "YF = torch.tensor(YF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = len(YW)\n",
    "\n",
    "XW = XW.repeat(timesteps, 1, 1)\n",
    "\n",
    "YF = YF.repeat(timesteps, 1, 1)\n",
    "XF = XF.repeat(timesteps, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Real Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dataset.pkl\", \"rb\") as f:\n",
    "    XF_r = [np.array(x) for x in pickle.load(f)]\n",
    "    YF_r = [np.array(x) for x in pickle.load(f)]\n",
    "                        \n",
    "    XW_r = [np.array(x) for x in pickle.load(f)]\n",
    "    YW_r = [np.array(x) for x in pickle.load(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "fig = plt.figure(figsize=(10, 10), dpi=100)\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "scat_f = plt.scatter(XF_r[0][:, 0], XF_r[0][:, 1], marker=\"s\", s=7, color=\"lightgreen\")\n",
    "\n",
    "scat_w = plt.scatter(XW_r[0][:, 0], XW_r[0][:, 1], marker=\"s\", s=20, c=[(0, 0, 0, 1)] * len(XW_r[0]))\n",
    "label = plt.text(0, 0, '', fontsize=12)\n",
    "\n",
    "# colors = []\n",
    "# for obs in YW:\n",
    "# #     min_v = min(obs)\n",
    "# #     max_v = max(obs)\n",
    "# #     colors.append([max((x - min_v) / (max_v - min_v), 0.1) for x in obs])\n",
    "#     colors.append([min(1 - abs(x) / 15, 1) for x in obs])\n",
    "\n",
    "# colors = np.array(colors)\n",
    "\n",
    "def update_plot(i, scat_w, scat_f):\n",
    "    scat_w.set_offsets(XW_r[i])\n",
    "    scat_w.set_array(np.array([min(1 - abs(x[0]) / 50, 1) for x in YW_r[i]]))\n",
    "    \n",
    "    scat_f.set_offsets(XF_r[i])\n",
    "    return scat_w, scat_f\n",
    "\n",
    "anim = animation.FuncAnimation(fig, update_plot, frames=range(len(XW_r)), fargs=(scat_w, scat_f), interval=1000)\n",
    "\n",
    "plt.gray()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Animation.save using <class 'matplotlib.animation.FFMpegWriter'>\n",
      "MovieWriter.run: running command: ['ffmpeg', '-f', 'rawvideo', '-vcodec', 'rawvideo', '-s', '1000x1000', '-pix_fmt', 'rgba', '-r', '1', '-loglevel', 'error', '-i', 'pipe:', '-vcodec', 'h264', '-pix_fmt', 'yuv420p', '-y', 'includes/data-animation.mp4']\n"
     ]
    }
   ],
   "source": [
    "anim.save(\"includes/data-animation.mp4\", fps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"includes/data-animation.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"includes/data-animation.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "26.4917, 71.4875]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "XF_r = [torch.tensor(x) for x in XF_r]\n",
    "YF_r = [torch.tensor(x[0]) for x in YF_r]\n",
    "\n",
    "XW_r = [torch.tensor(x) for x in XW_r]\n",
    "YW_r = [torch.tensor(x) for x in YW_r]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gp = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_file = \"data/sample-data/\" + (\"gp-samples\" if use_gp else \"kr-samples\") + \".json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF_distances = [pairwise_distances(XW_r[i], XF_r[i]) for i in range(len(YW_r))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sample: 100%|██████████| 500/500 [01:19<00:00,  6.27it/s, step size=3.15e-01, acc. prob=0.923]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(partial(model, WF_distances=WF_distances, gp=use_gp), max_plate_nesting=1)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "mcmc_run = mcmc.run(XW_r, YW_r, YF_r)\n",
    "\n",
    "samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ = {k: v.tolist() for k, v in samples.items()}\n",
    "with open(\"data/real-data/kr-samples.json\", \"w\") as f:\n",
    "    json.dump(samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WF_distances = [pairwise_distances(XW[i], XF[i]) for i in range(len(YW))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(partial(model, WF_distances=WF_distances, gp=use_gp))\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "mcmc_run = mcmc.run(XW, YW, YF)\n",
    "\n",
    "samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_ = {k: v.tolist() for k, v in samples.items()}\n",
    "with open(\"data/kr-samples2.json\", \"w\") as f:\n",
    "    json.dump(samples_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/real-data/kr-samples.json\", \"r\") as f:\n",
    "        samples = {k: np.array(v) for k, v in json.load(f).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(samples_file, \"r\") as f:\n",
    "        samples = {k: np.array(v) for k, v in json.load(f).items()}\n",
    "    \n",
    "except:\n",
    "    nuts_kernel = NUTS(partial(model, gp=use_gp))\n",
    "\n",
    "    mcmc = MCMC(nuts_kernel, num_samples=100, warmup_steps=400)\n",
    "    mcmc_run = mcmc.run(XW, YW)\n",
    "\n",
    "    samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Site: delta\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0  0.000219  0.000072  0.000126  0.000165  0.000201  0.000247  0.000356 \n",
      "\n",
      "Site: sigma\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0  23.180259  0.131626  22.958813  23.097648  23.183979  23.267464  23.403579 \n",
      "\n",
      "Site: theta_f\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0  0.000265  0.000086  0.000132  0.000203  0.000262  0.000314  0.000401 \n",
      "\n",
      "Site: sf\n",
      "       mean       std        5%       25%       50%       75%       95%\n",
      "0 -3.138915  0.499943 -4.043172 -3.460290 -3.067657 -2.799999 -2.419570\n",
      "1 -1.147099  0.480017 -2.015271 -1.437748 -1.138173 -0.858489 -0.361831\n",
      "2  1.178620  0.531882  0.373820  0.843479  1.159863  1.544441  1.960773 \n",
      "\n",
      "Site: mu_0\n",
      "        mean       std        5%        25%        50%        75%        95%\n",
      "0 -21.714631  0.541971 -22.63309 -22.088746 -21.655123 -21.364281 -20.847652 \n",
      "\n",
      "Site: mu_1\n",
      "        mean       std         5%        25%        50%       75%        95%\n",
      "0 -28.646124  0.591006 -29.633599 -29.023004 -28.630885 -28.27922 -27.632545 \n",
      "\n",
      "Site: mu_2\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -28.499884  0.661539 -29.635138 -29.044365 -28.464786 -27.936539 -27.468256 \n",
      "\n",
      "Site: mu_3\n",
      "        mean       std        5%        25%        50%       75%        95%\n",
      "0 -29.783194  0.565295 -30.71037 -30.144971 -29.786873 -29.40786 -28.873155 \n",
      "\n",
      "Site: mu_4\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -31.040136  0.623896 -32.117406 -31.464407 -31.027878 -30.615479 -29.967512 \n",
      "\n",
      "Site: mu_5\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -29.821158  0.672994 -30.913242 -30.269284 -29.833572 -29.379811 -28.683265 \n",
      "\n",
      "Site: mu_6\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -31.928276  0.632122 -32.833696 -32.426051 -31.985179 -31.560249 -30.897101 \n",
      "\n",
      "Site: mu_7\n",
      "        mean       std         5%       25%        50%        75%        95%\n",
      "0 -33.606402  0.532219 -34.423797 -34.03325 -33.630035 -33.306005 -32.657316 \n",
      "\n",
      "Site: mu_8\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -33.853215  0.559724 -34.770272 -34.224639 -33.903049 -33.421428 -32.991399 \n",
      "\n",
      "Site: mu_9\n",
      "        mean       std         5%       25%        50%        75%        95%\n",
      "0 -33.333716  0.565662 -34.299764 -33.69089 -33.362728 -33.029337 -32.416225 \n",
      "\n",
      "Site: mu_10\n",
      "        mean       std         5%        25%       50%        75%        95%\n",
      "0 -35.552689  0.504968 -36.357264 -35.904923 -35.53479 -35.209888 -34.732351 \n",
      "\n",
      "Site: mu_11\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -35.504731  0.606408 -36.494316 -35.952443 -35.471069 -35.037113 -34.569045 \n",
      "\n",
      "Site: mu_12\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -35.692922  0.546452 -36.540282 -36.059909 -35.731365 -35.302051 -34.818706 \n",
      "\n",
      "Site: mu_13\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -34.421213  0.615499 -35.382604 -34.893326 -34.442276 -34.003528 -33.376303 \n",
      "\n",
      "Site: mu_14\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -31.916091  0.740406 -33.027245 -32.326372 -31.979035 -31.477441 -30.659739 \n",
      "\n",
      "Site: mu_15\n",
      "        mean       std         5%       25%        50%        75%        95%\n",
      "0 -33.143873  0.630929 -34.232493 -33.53008 -33.119669 -32.746391 -32.258992 \n",
      "\n",
      "Site: mu_16\n",
      "        mean       std         5%        25%        50%       75%        95%\n",
      "0 -33.128191  0.662445 -34.301501 -33.542314 -33.118994 -32.59955 -32.242447 \n",
      "\n",
      "Site: mu_17\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -31.632156  0.629547 -32.829656 -31.979814 -31.590194 -31.153629 -30.691713 \n",
      "\n",
      "Site: mu_18\n",
      "        mean       std         5%        25%        50%        75%       95%\n",
      "0 -33.007283  0.727665 -34.067986 -33.475559 -33.048405 -32.624427 -31.73063 \n",
      "\n",
      "Site: mu_19\n",
      "        mean       std         5%        25%        50%       75%        95%\n",
      "0 -32.687191  0.670563 -33.761149 -33.081245 -32.764666 -32.30025 -31.558958 \n",
      "\n",
      "Site: mu_20\n",
      "        mean      std         5%        25%       50%        75%        95%\n",
      "0 -28.513347  0.88219 -29.784528 -29.159029 -28.54019 -27.958255 -27.023804 \n",
      "\n",
      "Site: mu_21\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -29.443782  0.841909 -30.730762 -29.986626 -29.555879 -28.967354 -28.219959 \n",
      "\n",
      "Site: mu_22\n",
      "        mean       std         5%        25%        50%        75%        95%\n",
      "0 -29.414339  0.936109 -31.151347 -30.089602 -29.187251 -28.744856 -28.079265 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for site, values in summary(samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site, values in summary(samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
