{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Kriging to Predict Ground Water Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os\n",
    "import pyro\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyro.optim as optim\n",
    "import pyro.contrib.gp as gp\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro.distributions as dist\n",
    "\n",
    "from torch.distributions import constraints\n",
    "\n",
    "from pyro.infer.mcmc import NUTS\n",
    "from pyro.infer.mcmc.api import MCMC\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pyro.contrib.autoguide import AutoMultivariateNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, JitTrace_ELBO\n",
    "\n",
    "pyro.set_rng_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "logging.basicConfig(format=\"%(message)s\", level=logging.INFO)\n",
    "\n",
    "# Enable validation checks\n",
    "pyro.enable_validation(True)\n",
    "smoke_test = \"CI\" in os.environ\n",
    "assert pyro.__version__.startswith(\"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.set_rng_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(x, y=None):\n",
    "    '''\n",
    "    Input: x is a Nxd matrix\n",
    "           y is an optional Mxd matirx\n",
    "    Output: dist is a NxM matrix where dist[i,j] is the square norm between x[i,:] and y[j,:]\n",
    "            if y is not given then use 'y=x'.\n",
    "    i.e. dist[i,j] = ||x[i,:]-y[j,:]||^2\n",
    "    '''\n",
    "    x_norm = (x**2).sum(1).view(-1, 1)\n",
    "    if y is not None:\n",
    "        y_t = torch.transpose(y, 0, 1)\n",
    "        y_norm = (y**2).sum(1).view(1, -1)\n",
    "    else:\n",
    "        y_t = torch.transpose(x, 0, 1)\n",
    "        y_norm = x_norm.view(1, -1)\n",
    "    \n",
    "    dist = x_norm + y_norm - 2.0 * torch.mm(x, y_t)\n",
    "    # Ensure diagonal is zero if x=y\n",
    "    # if y is None:\n",
    "    #     dist = dist - torch.diag(dist.diag)\n",
    "    return torch.clamp(dist, 0.0, np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(\n",
    "    plot_observed_data=False,\n",
    "    plot_predictions=False,\n",
    "    n_prior_samples=0,\n",
    "    model=None,\n",
    "    kernel=None,\n",
    "    n_test=500,\n",
    "):\n",
    "\n",
    "    ax = plt.figure().add_subplot(111, projection='3d')\n",
    "    \n",
    "    if plot_observed_data:\n",
    "        ax.scatter(XW[:, 0], XW[:, 1], YW, marker=\"x\")\n",
    "        ax.scatter(XF[:, 0], XF[:, 1], YF, marker=\"o\")\n",
    "        \n",
    "    if plot_predictions:\n",
    "        Xtest_ltd = torch.linspace(0, 5, n_test)\n",
    "        Xtest_lng = torch.linspace(0, 10, n_test)\n",
    "        \n",
    "        Xtest_ltd, Xtest_lng = np.meshgrid(Xtest_ltd, Xtest_lng)\n",
    "        \n",
    "        Xtest_ltd = np.expand_dims(Xtest_ltd, -1)\n",
    "        Xtest_lng = np.expand_dims(Xtest_lng, -1)\n",
    "        \n",
    "        Xtest = np.concatenate([Xtest_ltd, Xtest_lng], -1).reshape((-1, 2))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if type(model) == gp.models.VariationalSparseGP:\n",
    "                mean, cov = model(Xtest, full_cov=True)\n",
    "            else:\n",
    "                mean, cov = model(Xtest, full_cov=True, noiseless=False)\n",
    "                \n",
    "        print(mean, cov)\n",
    "                \n",
    "        sd = cov.diag().sqrt()  # standard deviation at each input point x\n",
    "        plt.plot(Xtest.numpy(), mean.numpy(), \"r\", lw=2)  # plot the mean\n",
    "        plt.fill_between(\n",
    "            Xtest,  # plot the two-sigma uncertainty about the mean\n",
    "            (mean - 2.0 * sd).numpy(),\n",
    "            (mean + 2.0 * sd).numpy(),\n",
    "            color=\"C0\",\n",
    "            alpha=0.3,\n",
    "        )\n",
    "        \n",
    "    if n_prior_samples > 0:  # plot samples from the GP prior\n",
    "        Xtest_ltd = torch.linspace(0, 5, n_test)\n",
    "        Xtest_lng = torch.linspace(0, 10, n_test)\n",
    "        \n",
    "        Xtest_ltd, Xtest_lng = np.meshgrid(Xtest_ltd, Xtest_lng)\n",
    "        \n",
    "        Xtest_ltd = np.expand_dims(Xtest_ltd, -1)\n",
    "        Xtest_lng = np.expand_dims(Xtest_lng, -1)\n",
    "        \n",
    "        Xtest = np.concatenate([Xtest_ltd, Xtest_lng], -1).reshape((-1, 2))\n",
    "        Xtest = torch.tensor(Xtest)\n",
    "        \n",
    "        noise = (\n",
    "            model.noise\n",
    "            if type(model) != gp.models.VariationalSparseGP\n",
    "            else model.likelihood.variance\n",
    "        )\n",
    "        cov = kernel.forward(Xtest) + noise.expand(n_test).diag()\n",
    "        samples = dist.MultivariateNormal(\n",
    "            torch.zeros(n_test), covariance_matrix=cov\n",
    "        ).sample(sample_shape=(n_prior_samples,))\n",
    "        plt.plot(Xtest.numpy(), samples.numpy().T, lw=2, alpha=0.4)\n",
    "\n",
    "#     plt.xlim(-0.5, 5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_posterior(samples):\n",
    "    import math\n",
    "    \n",
    "    sites = list(samples.keys())\n",
    "    \n",
    "    r = int(math.ceil(math.sqrt(len(samples))))\n",
    "    fig, axs = plt.subplots(nrows=r, ncols=r, figsize=(12, 10))\n",
    "    fig.suptitle(\"Marginal Posterior Density\", fontsize=16)\n",
    "    \n",
    "    \n",
    "    for i, ax in enumerate(axs.reshape(-1)):\n",
    "        site = sites[i]\n",
    "        sns.distplot(samples[site], ax=ax)\n",
    "        ax.set_title(site)\n",
    "        \n",
    "    handles, labels = ax.get_legend_handles_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/sample_data.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "data_wells = data[data.type == \"well\"]\n",
    "data_farms = data[data.type == \"farm\"]\n",
    "\n",
    "XW = torch.tensor(data_wells[[\"latitude\", \"longitude\"]].values)\n",
    "YW = torch.tensor(data_wells[\"observation\"].values)\n",
    "\n",
    "XF = torch.tensor(data_farms[[\"latitude\", \"longitude\"]].values)\n",
    "YF = torch.tensor(data_farms[\"observation\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(plot_observed_data=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Kernel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def model(XW, YW):\n",
    "    mu_delta = 1\n",
    "    mu_theta = 0\n",
    "    \n",
    "    delta = -pyro.sample(\"delta\", dist.LogNormal(mu_delta, 0.5))\n",
    "    theta = pyro.sample(\"theta\", dist.LogNormal(mu_theta, 0.5))\n",
    "    \n",
    "    sigma_mu = 2\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(0, sigma_mu))\n",
    "    \n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(1, 1))\n",
    "    mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu\n",
    "    \n",
    "    with pyro.plate(\"data\", len(YW)):\n",
    "        y = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=YW)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def guide(XW, YW):\n",
    "    weights_loc = pyro.param('weights_loc', torch.randn(4))\n",
    "    weights_scale = pyro.param('weights_scale', torch.ones(4), constraint=constraints.positive)        \n",
    "\n",
    "    mu_delta = pyro.param(\"mu_delta\", torch.ones(1), constraint=constraints.positive)\n",
    "    mu_theta = pyro.param(\"mu_theta\", torch.zeros(1), constraint=constraints.positive)\n",
    "    \n",
    "    sg_delta = pyro.param('sg_delta', torch.ones(1), constraint=constraints.positive)\n",
    "    sg_theta = pyro.param('sg_theta', torch.ones(1), constraint=constraints.positive)\n",
    "    \n",
    "    delta = -pyro.sample(\"delta\", dist.Normal(mu_delta, sg_delta))\n",
    "    theta = pyro.sample(\"theta\", dist.Normal(mu_theta, sg_theta))\n",
    "    \n",
    "    mu_sigma = pyro.param('mu_sigma', torch.tensor(1.0), constraint=constraints.positive)\n",
    "    sigma = pyro.sample(\"sigma\", dist.Normal(mu_sigma, torch.tensor(0.05)))\n",
    "    \n",
    "    mu_mu = pyro.param(\"mu_mu\", torch.randn(1))\n",
    "    sg_mu = pyro.param('sg_mu', torch.ones(1), constraint=constraints.positive)\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(mu_mu, sg_mu))\n",
    "    \n",
    "    mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def predict(XW, posterior_samples):\n",
    "    ps = posterior_samples\n",
    "    samples = zip(ps[\"delta\"], ps[\"theta\"], ps[\"mu\"], ps[\"sigma\"])\n",
    "    \n",
    "    for delta, theta, mu, sigma in samples:\n",
    "        mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu\n",
    "        yield dist.Normal(mean, sigma).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc_run = mcmc.run(XW, YW)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "visualize_posterior(hmc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# svi = SVI(\n",
    "#     model, guide, optim.Adam({\"lr\": 0.005}), loss=JitTrace_ELBO(), num_samples=1000\n",
    "# )\n",
    "\n",
    "# pyro.clear_param_store()\n",
    "# num_iters = 10000 if not smoke_test else 2\n",
    "# for i in range(num_iters):\n",
    "#     elbo = svi.step(XW, YW)\n",
    "#     if i % 500 == 0:\n",
    "#         logging.info(\"Elbo loss: {}\".format(elbo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.stack(list(predict(XW, hmc_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], YW, marker=\"x\")\n",
    "ax.scatter(XF[:, 0], XF[:, 1], YF, marker=\"^\")\n",
    "\n",
    "# for result in results[:100]:\n",
    "#     ax.scatter(XW[:, 0], XW[:, 1], result, marker=\".\", color=\"red\")\n",
    "    \n",
    "results_mean = results.mean(dim=0).numpy()\n",
    "results_std = results.std(dim=0).numpy()\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean, marker=\"o\", color=\"red\", s=15)\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean - results_std, marker=\"_\", color=\"green\", s=15)\n",
    "# for i, point in enumerate(XW.numpy().tolist()):\n",
    "#     ax.plot(point + [results_mean[i] + results_std[i]], point + [results_mean[i] - results_std[i]])\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean + results_std, marker=\"_\", color=\"green\", s=15)\n",
    "    \n",
    "plt.savefig(\"predictions.png\", dpi=240)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(XW, YW):\n",
    "    mu_delta = 1\n",
    "    mu_theta = 0\n",
    "    \n",
    "    delta = -pyro.sample(\"delta\", dist.LogNormal(mu_delta, 0.5))\n",
    "    theta = pyro.sample(\"theta\", dist.LogNormal(mu_theta, 0.5))\n",
    "    \n",
    "    sigma_mu = 2\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(0, sigma_mu))\n",
    "    \n",
    "    sigma = pyro.sample(\"sigma\", dist.Gamma(1, 1))\n",
    "    mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu\n",
    "    \n",
    "    with pyro.plate(\"data\", len(YW)):\n",
    "        y = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=YW)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(XW, YW):\n",
    "    weights_loc = pyro.param('weights_loc', torch.randn(4))\n",
    "    weights_scale = pyro.param('weights_scale', torch.ones(4), constraint=constraints.positive)        \n",
    "\n",
    "    mu_delta = pyro.param(\"mu_delta\", torch.ones(1), constraint=constraints.positive)\n",
    "    mu_theta = pyro.param(\"mu_theta\", torch.zeros(1), constraint=constraints.positive)\n",
    "    \n",
    "    sg_delta = pyro.param('sg_delta', torch.ones(1), constraint=constraints.positive)\n",
    "    sg_theta = pyro.param('sg_theta', torch.ones(1), constraint=constraints.positive)\n",
    "    \n",
    "    delta = -pyro.sample(\"delta\", dist.Normal(mu_delta, sg_delta))\n",
    "    theta = pyro.sample(\"theta\", dist.Normal(mu_theta, sg_theta))\n",
    "    \n",
    "    sigma_loc = pyro.param('sigma_loc', torch.tensor(1.0), constraint=constraints.positive)\n",
    "    sigma = pyro.sample(\"sigma\", dist.Normal(sigma_loc, torch.tensor(0.05)))\n",
    "    \n",
    "    mu_sigma = pyro.param('mu_sigma', torch.tensor(1.0), constraint=constraints.positive)\n",
    "    sigma = pyro.sample(\"sigma\", dist.Normal(mu_sigma, torch.tensor(0.05)))\n",
    "    \n",
    "    mu_mu = pyro.param(\"mu_mu\", torch.randn(1))\n",
    "    sg_mu = pyro.param('sg_mu', torch.ones(1), constraint=constraints.positive)\n",
    "    mu = pyro.sample(\"mu\", dist.Normal(mu_mu, sg_mu))\n",
    "    \n",
    "    mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(XW, posterior_samples):\n",
    "    ps = posterior_samples\n",
    "    samples = zip(ps[\"delta\"], ps[\"theta\"], ps[\"mu\"], ps[\"sigma\"])\n",
    "    \n",
    "    for delta, theta, mu, sigma in samples:\n",
    "        mean = (YF * torch.exp(-pairwise_distances(XW, XF) / theta)).sum(1) * delta + mu\n",
    "        yield dist.Normal(mean, sigma).sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc_run = mcmc.run(XW, YW)\n",
    "\n",
    "hmc_samples = {k: v.detach().cpu().numpy() for k, v in mcmc.get_samples().items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for site, values in summary(hmc_samples).items():\n",
    "    print(\"Site: {}\".format(site))\n",
    "    print(values, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_posterior(hmc_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.stack(list(predict(XW, hmc_samples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure(figsize=(8, 8)).add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], YW, marker=\"x\")\n",
    "ax.scatter(XF[:, 0], XF[:, 1], YF, marker=\"^\")\n",
    "\n",
    "# for result in results[:100]:\n",
    "#     ax.scatter(XW[:, 0], XW[:, 1], result, marker=\".\", color=\"red\")\n",
    "    x\n",
    "results_mean = results.mean(dim=0).numpy()\n",
    "results_std = results.std(dim=0).numpy()\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean, marker=\"o\", color=\"red\", s=15)\n",
    "\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean - results_std, marker=\"_\", color=\"green\", s=15)\n",
    "# for i, point in enumerate(XW.numpy().tolist()):\n",
    "#     ax.plot(point + [results_mean[i] + results_std[i]], point + [results_mean[i] - results_std[i]])\n",
    "ax.scatter(XW[:, 0], XW[:, 1], results_mean + results_std, marker=\"_\", color=\"green\", s=15)\n",
    "    \n",
    "plt.savefig(\"predictions.png\", dpi=240)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
